{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model using binarized data\n",
    "\n",
    "We will finally train a logistic regression model using the binarized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import helpers_models as hm\n",
    "from binarized_transforms import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load the data. This data has different columns than the data we worked with before. It will required different transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle('../data/binarized_data.pkl').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">23</th>\n",
       "      <th colspan=\"6\" halign=\"left\">24</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">36</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>other_hashtags</th>\n",
       "      <th>other_mentions</th>\n",
       "      <th>other_urls</th>\n",
       "      <th>tweets</th>\n",
       "      <th>hashtag_1:</th>\n",
       "      <th>hashtag_Aerotek</th>\n",
       "      <th>hashtag_BSB</th>\n",
       "      <th>mention_\"\"</th>\n",
       "      <th>other_hashtags</th>\n",
       "      <th>other_mentions</th>\n",
       "      <th>...</th>\n",
       "      <th>hashtag_jobs</th>\n",
       "      <th>hashtag_shjobs</th>\n",
       "      <th>mention_\"\"</th>\n",
       "      <th>mention_justinbieber</th>\n",
       "      <th>other_hashtags</th>\n",
       "      <th>other_mentions</th>\n",
       "      <th>other_urls</th>\n",
       "      <th>tweets</th>\n",
       "      <th>url_http://eepurl.com/dgVR</th>\n",
       "      <th>url_http://www.accuweather.com/twtr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bdogg</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000000</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000000000111</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000000101010</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 717 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            23                                          24  \\\n",
       "                other_hashtags other_mentions other_urls tweets hashtag_1:   \n",
       "user                                                                         \n",
       " bdogg                       0              0          0      0          0   \n",
       "0                            0              0          0      0          0   \n",
       "00000000                     0              0          0      0          0   \n",
       "000000000000111              0              0          0      0          0   \n",
       "000000000101010              0              0          0      0          0   \n",
       "\n",
       "                                                                       \\\n",
       "                hashtag_Aerotek hashtag_BSB mention_\"\" other_hashtags   \n",
       "user                                                                    \n",
       " bdogg                        0           0          0              0   \n",
       "0                             0           0          0              0   \n",
       "00000000                      0           0          0              0   \n",
       "000000000000111               0           0          0              0   \n",
       "000000000101010               0           0          0              0   \n",
       "\n",
       "                                               ...                  \\\n",
       "                other_mentions                 ...                   \n",
       "user                                           ...                   \n",
       " bdogg                       0                 ...                   \n",
       "0                            0                 ...                   \n",
       "00000000                     0                 ...                   \n",
       "000000000000111              0                 ...                   \n",
       "000000000101010              0                 ...                   \n",
       "\n",
       "                          36                                                 \\\n",
       "                hashtag_jobs hashtag_shjobs mention_\"\" mention_justinbieber   \n",
       "user                                                                          \n",
       " bdogg                     0              0          0                    0   \n",
       "0                          0              0          0                    0   \n",
       "00000000                   0              0          0                    0   \n",
       "000000000000111            0              0          0                    0   \n",
       "000000000101010            0              0          0                    0   \n",
       "\n",
       "                                                                 \\\n",
       "                other_hashtags other_mentions other_urls tweets   \n",
       "user                                                              \n",
       " bdogg                       0              0          0      2   \n",
       "0                            0              0          0      0   \n",
       "00000000                     0              0          0      1   \n",
       "000000000000111              0              0          0      0   \n",
       "000000000101010              0              0          0      0   \n",
       "\n",
       "                                                                                \n",
       "                url_http://eepurl.com/dgVR url_http://www.accuweather.com/twtr  \n",
       "user                                                                            \n",
       " bdogg                                   0                                   0  \n",
       "0                                        0                                   0  \n",
       "00000000                                 0                                   0  \n",
       "000000000000111                          0                                   0  \n",
       "000000000101010                          0                                   0  \n",
       "\n",
       "[5 rows x 717 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now set the starting and the target week. Considering the results on the chart we made of weeks taken the accuracy, we will take 11 weeks of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_week = data.columns.levels[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_week = target_week - 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will be using weeks 25 to 35 to train the model for the target week 36\n"
     ]
    }
   ],
   "source": [
    "print('We will be using weeks', start_week, 'to', target_week - 1, 'to train the model for the target week', target_week)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we make a pipeline, let's transform and pre-process the data. These transforms also need to modify the target column so they can't be used in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TargetMaker(target_week=target_week).transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And balance the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ClassBalancer().fit_transform(train, train[['target']].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('limiter', WeeksLimiter(start_week, target_week)),\n",
    "    ('normal', Normalizer()),\n",
    "    ('decay', TimeDecayApplier(target_week)),\n",
    "    ('logreg', LogisticRegressionCV(max_iter=300, n_jobs=-1, verbose=2))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decay': TimeDecayApplier(target_week=36),\n",
       " 'decay__target_week': 36,\n",
       " 'limiter': WeeksLimiter(start_week=25, target_week=36),\n",
       " 'limiter__start_week': 25,\n",
       " 'limiter__target_week': 36,\n",
       " 'logreg': LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1.0, max_iter=200,\n",
       "            multi_class='ovr', n_jobs=-1, penalty='l2', random_state=None,\n",
       "            refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=2),\n",
       " 'logreg__Cs': 10,\n",
       " 'logreg__class_weight': None,\n",
       " 'logreg__cv': None,\n",
       " 'logreg__dual': False,\n",
       " 'logreg__fit_intercept': True,\n",
       " 'logreg__intercept_scaling': 1.0,\n",
       " 'logreg__max_iter': 200,\n",
       " 'logreg__multi_class': 'ovr',\n",
       " 'logreg__n_jobs': -1,\n",
       " 'logreg__penalty': 'l2',\n",
       " 'logreg__random_state': None,\n",
       " 'logreg__refit': True,\n",
       " 'logreg__scoring': None,\n",
       " 'logreg__solver': 'lbfgs',\n",
       " 'logreg__tol': 0.0001,\n",
       " 'logreg__verbose': 2,\n",
       " 'normal': Normalizer(),\n",
       " 'steps': [('limiter', WeeksLimiter(start_week=25, target_week=36)),\n",
       "  ('normal', Normalizer()),\n",
       "  ('decay', TimeDecayApplier(target_week=36)),\n",
       "  ('logreg',\n",
       "   LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
       "              fit_intercept=True, intercept_scaling=1.0, max_iter=200,\n",
       "              multi_class='ovr', n_jobs=-1, penalty='l2', random_state=None,\n",
       "              refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=2))]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:717: UserWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"lbfgs failed to converge. Increase the number \"\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:717: UserWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"lbfgs failed to converge. Increase the number \"\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:717: UserWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"lbfgs failed to converge. Increase the number \"\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  5.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 4s, sys: 17.3 s, total: 2min 22s\n",
      "Wall time: 6min 33s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('limiter', WeeksLimiter(start_week=25, target_week=36)), ('normal', Normalizer()), ('decay', TimeDecayApplier(target_week=36)), ('logreg', LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=200,\n",
       "           multi_class='ovr', n_jobs=-1, penalty='l2', random_state=None,\n",
       "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=2))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pipeline.fit(train.drop('target', axis=1), train[['target']].values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test the accuracy of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.91      0.95      0.92    249523\n",
      "       True       0.36      0.24      0.29     32477\n",
      "\n",
      "avg / total       0.84      0.86      0.85    282000\n",
      "\n",
      "CPU times: user 26.3 s, sys: 750 ms, total: 27 s\n",
      "Wall time: 26.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predicted = pipeline.predict(test.drop('target', axis=1))\n",
    "report = classification_report(test[['target']].values.ravel(), predicted)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search\n",
    "\n",
    "In this notebook we will do a grid search to optimize the best parameters and preprocessing of the data and the logistic regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import helpers_models as hm\n",
    "from binarized_transforms import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle('../data/binarized_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search will take a long time to train so we will only take a small subset of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.sample(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the target and the starting weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_week = data.columns.levels[0].max()\n",
    "target_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_week = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the target and split the data into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = TargetMaker(target_week=target_week).transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balance the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = ClassBalancer().fit_transform(train, train[['target']].values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make the pipeline. The parameters of this pipeline will be optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('limiter', WeeksLimiter(start_week, target_week)),\n",
    "    ('normal', Normalizer()),\n",
    "    ('decay', TimeDecayApplier(target_week)),\n",
    "    ('pca', PCA(0.95)),\n",
    "    ('logreg', LogisticRegression(verbose=2, solver='sag'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decay': TimeDecayApplier(ignore_binarized_columns=True, skip=False, target_week=36,\n",
       "          verbose=False),\n",
       " 'decay__ignore_binarized_columns': True,\n",
       " 'decay__skip': False,\n",
       " 'decay__target_week': 36,\n",
       " 'decay__verbose': False,\n",
       " 'limiter': WeeksLimiter(start_week=25, target_week=36),\n",
       " 'limiter__start_week': 25,\n",
       " 'limiter__target_week': 36,\n",
       " 'logreg': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "           verbose=2, warm_start=False),\n",
       " 'logreg__C': 1.0,\n",
       " 'logreg__class_weight': None,\n",
       " 'logreg__dual': False,\n",
       " 'logreg__fit_intercept': True,\n",
       " 'logreg__intercept_scaling': 1,\n",
       " 'logreg__max_iter': 100,\n",
       " 'logreg__multi_class': 'ovr',\n",
       " 'logreg__n_jobs': 1,\n",
       " 'logreg__penalty': 'l2',\n",
       " 'logreg__random_state': None,\n",
       " 'logreg__solver': 'sag',\n",
       " 'logreg__tol': 0.0001,\n",
       " 'logreg__verbose': 2,\n",
       " 'logreg__warm_start': False,\n",
       " 'normal': Normalizer(ignore_binarized_columns=True, skip=False, verbose=False),\n",
       " 'normal__ignore_binarized_columns': True,\n",
       " 'normal__skip': False,\n",
       " 'normal__verbose': False,\n",
       " 'pca': PCA(copy=True, iterated_power='auto', n_components=0.95, random_state=None,\n",
       "   svd_solver='auto', tol=0.0, whiten=False),\n",
       " 'pca__copy': True,\n",
       " 'pca__iterated_power': 'auto',\n",
       " 'pca__n_components': 0.95,\n",
       " 'pca__random_state': None,\n",
       " 'pca__svd_solver': 'auto',\n",
       " 'pca__tol': 0.0,\n",
       " 'pca__whiten': False,\n",
       " 'steps': [('limiter', WeeksLimiter(start_week=25, target_week=36)),\n",
       "  ('normal',\n",
       "   Normalizer(ignore_binarized_columns=True, skip=False, verbose=False)),\n",
       "  ('decay',\n",
       "   TimeDecayApplier(ignore_binarized_columns=True, skip=False, target_week=36,\n",
       "            verbose=False)),\n",
       "  ('pca',\n",
       "   PCA(copy=True, iterated_power='auto', n_components=0.95, random_state=None,\n",
       "     svd_solver='auto', tol=0.0, whiten=False)),\n",
       "  ('logreg',\n",
       "   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "             penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "             verbose=2, warm_start=False))]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are a lot of params that can be optimized using grid search. Let's define the options for grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    # weeks limiter params\n",
    "    'limiter__start_week': [23, 25, 30, 32],\n",
    "    \n",
    "    # normalizer params\n",
    "    'normal__skip': [False, True],\n",
    "    'normal__ignore_binarized_columns': [False, True],\n",
    "    \n",
    "    # time decay applier params\n",
    "    'decay__skip': [False, True],\n",
    "    'decay__ignore_binarized_columns': [False, True],\n",
    "    \n",
    "    # PCA params\n",
    "    'pca__n_components': [0.95, 1.0],\n",
    "    \n",
    "    # logistic regression params\n",
    "    'logreg__C': [0.2, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the grid search to optimize the params and train the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = GridSearchCV(pipeline, params, n_jobs=-1, pre_dispatch='2*n_jobs', verbose=2, error_score=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 256 candidates, totalling 768 fits\n",
      "[CV] decay__ignore_binarized_columns=False, decay__skip=False, limiter__start_week=23, logreg__C=0.2, normal__ignore_binarized_columns=False, normal__skip=False, pca__n_components=0.95 \n",
      "[CV] decay__ignore_binarized_columns=False, decay__skip=False, limiter__start_week=23, logreg__C=0.2, normal__ignore_binarized_columns=False, normal__skip=False, pca__n_components=0.95 \n",
      "[CV] decay__ignore_binarized_columns=False, decay__skip=False, limiter__start_week=23, logreg__C=0.2, normal__ignore_binarized_columns=False, normal__skip=False, pca__n_components=0.95 \n",
      "[CV] decay__ignore_binarized_columns=False, decay__skip=False, limiter__start_week=23, logreg__C=0.2, normal__ignore_binarized_columns=False, normal__skip=False, pca__n_components=1.0 \n",
      "[CV] decay__ignore_binarized_columns=False, decay__skip=False, limiter__start_week=23, logreg__C=0.2, normal__ignore_binarized_columns=False, normal__skip=False, pca__n_components=1.0 \n",
      "[CV] decay__ignore_binarized_columns=False, decay__skip=False, limiter__start_week=23, logreg__C=0.2, normal__ignore_binarized_columns=False, normal__skip=False, pca__n_components=1.0 \n",
      "[CV] decay__ignore_binarized_columns=False, decay__skip=False, limiter__start_week=23, logreg__C=0.2, normal__ignore_binarized_columns=False, normal__skip=True, pca__n_components=0.95 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../scripts/binarized_transforms.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  data[(week, column)] = data[(week, column)] / time_decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] decay__ignore_binarized_columns=False, decay__skip=False, limiter__start_week=23, logreg__C=0.2, normal__ignore_binarized_columns=False, normal__skip=True, pca__n_components=0.95 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../scripts/binarized_transforms.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  data[(week, column)] = data[(week, column)] / time_decay\n",
      "../scripts/binarized_transforms.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  data[(week, column)] = data[(week, column)].div(self.column_sums[(week, column)]).fillna(0)\n",
      "../scripts/binarized_transforms.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  data[(week, column)] = data[(week, column)].div(self.column_sums[(week, column)]).fillna(0)\n",
      "../scripts/binarized_transforms.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  data[(week, column)] = data[(week, column)].div(self.column_sums[(week, column)]).fillna(0)\n",
      "../scripts/binarized_transforms.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  data[(week, column)] = data[(week, column)].div(self.column_sums[(week, column)]).fillna(0)\n",
      "../scripts/binarized_transforms.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  data[(week, column)] = data[(week, column)].div(self.column_sums[(week, column)]).fillna(0)\n",
      "../scripts/binarized_transforms.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  data[(week, column)] = data[(week, column)].div(self.column_sums[(week, column)]).fillna(0)\n"
     ]
    }
   ],
   "source": [
    "model.fit(train.drop('target', axis=1), train[['target']].values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now the parameters are learned, let's check them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute `cv_results_` also contains the tried combinations and the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(model.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, test the model on the test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "predicted = model.predict(test.drop('target', axis=1))\n",
    "report = classification_report(test[['target']].values.ravel(), predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

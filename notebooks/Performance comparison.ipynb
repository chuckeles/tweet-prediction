{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance comparison\n",
    "\n",
    "In this notebook, we will train logistic regression, naive bayes, and decision tree on the same data. We will compare their performance in terms of the final score but also the time it takes to train the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import helpers_models as hm\n",
    "from transforms import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare the data sample we will train and test on. We want to use the same data for all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_hdf('../data/pivot_numbers_only.h5', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_week = data['tweets'].columns.max()\n",
    "target_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_week = data['tweets'].columns.min()\n",
    "first_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = hm.make_target(data, target_week)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training, let's balance the dataset and use a small sample of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = hm.balance_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1434270, 53)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a pipeline to process the data. All models will use the data transformed by this pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_pipe = Pipeline([\n",
    "    ('limiter', WeeksLimiter(first_week, target_week)),\n",
    "    ('normal', Normalizer()),\n",
    "    ('decay', TimeDecayApplier(target_week))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now transform train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_target = train.target\n",
    "train = data_pipe.fit_transform(train.drop('target', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_target = test.target\n",
    "test = data_pipe.fit_transform(test.drop('target', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the normalization and the time decay and we will use 13 weeks of data for training. We ran grid search algorithms for each model before so now we know what to choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.91 s, sys: 429 ms, total: 4.34 s\n",
      "Wall time: 4.34 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logistic.fit(train, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.19 s, sys: 602 ms, total: 1.79 s\n",
      "Wall time: 1.79 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "bayes.fit(train, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.7 s, sys: 157 ms, total: 31.9 s\n",
      "Wall time: 31.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tree.fit(train, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False    0.50234   0.99972   0.66868    238966\n",
      "       True    0.97335   0.01023   0.02025    239124\n",
      "\n",
      "avg / total    0.73792   0.50481   0.34436    478090\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = logistic.predict(test)\n",
    "print(classification_report(test_target, predicted, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False    0.59833   0.94372   0.73234    238966\n",
      "       True    0.86707   0.36687   0.51559    239124\n",
      "\n",
      "avg / total    0.73274   0.65520   0.62393    478090\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = bayes.predict(test)\n",
    "print(classification_report(test_target, predicted, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False    0.69523   0.76875   0.73014    238966\n",
      "       True    0.74159   0.66322   0.70022    239124\n",
      "\n",
      "avg / total    0.71842   0.71597   0.71517    478090\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = tree.predict(test)\n",
    "print(classification_report(test_target, predicted, digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What attributes were chosen as the main predictors? For the logistic regression, we select the features with coeficients larger than the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17718191220339319"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs = np.abs(logistic.coef_[0])\n",
    "coef_mean = coefs.mean()\n",
    "coef_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(31, 'mentions'),\n",
       " (32, 'hashtags'),\n",
       " (32, 'mentions'),\n",
       " (32, 'tweets'),\n",
       " (32, 'urls'),\n",
       " (33, 'hashtags'),\n",
       " (33, 'mentions'),\n",
       " (33, 'tweets'),\n",
       " (33, 'urls'),\n",
       " (34, 'hashtags'),\n",
       " (34, 'mentions'),\n",
       " (34, 'tweets'),\n",
       " (34, 'urls'),\n",
       " (35, 'hashtags'),\n",
       " (35, 'mentions'),\n",
       " (35, 'tweets'),\n",
       " (35, 'urls')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = test[np.where(coefs > coef_mean)[0]].columns.values\n",
    "list(sorted(map(lambda x: (x[1], x[0]), columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the naive bayes classifier is only using the probabilities of classes and features, it does not prefer any specific feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.50005508,  0.49994492])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes.class_prior_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019230769230769232"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp = tree.feature_importances_\n",
    "imp_mean = imp.mean()\n",
    "imp_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(30, 'tweets'),\n",
       " (31, 'tweets'),\n",
       " (31, 'urls'),\n",
       " (32, 'urls'),\n",
       " (33, 'mentions'),\n",
       " (33, 'tweets'),\n",
       " (33, 'urls'),\n",
       " (34, 'mentions'),\n",
       " (34, 'tweets'),\n",
       " (34, 'urls'),\n",
       " (35, 'mentions'),\n",
       " (35, 'tweets'),\n",
       " (35, 'urls')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = test[np.where(imp > imp_mean)[0]].columns.values\n",
    "list(sorted(map(lambda x: (x[1], x[0]), columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Logistic regression performs poorly and overfits the data easily. Although it has the best precision, the recall and the F1 score are the worst. The model fits the data quickly.\n",
    "\n",
    "Naive bayes has slightly worse precision, better recall, and almost twice as high F1 score. It takes half the time to fit, performs pretty good.\n",
    "\n",
    "Decision tree has the best scores. It takes the longest to fit, ten times as long as logistic regression. It has worse precision than both models, the best recall and F1 score by far.\n",
    "\n",
    "Both logistic regression and decision tree prefer features from weeks 30, 31, and afterwards."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance comparison\n",
    "\n",
    "In this notebook, we will train logistic regression, naive bayes, and decision tree on the same data. We will compare their performance in terms of the final score but also the time it takes to train the models. We vary the amount of weeks and the preprocessing steps and observe the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from timeit import default_timer as timer\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import helpers_models as hm\n",
    "from transforms import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Let's prepare the data sample we will train and test on. We want to use the same data for all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_hdf('../data/pivot_numbers_only.h5', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_week = data['tweets'].columns.max()\n",
    "target_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = hm.make_target(data, target_week)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training, let's balance the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = hm.balance_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1912360, 53)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation function\n",
    "\n",
    "Now we want to define a function that allows us to easily configure the parameters and train all 3 classifiers. The function should accept a dataset, a set of parameters, and return the resulting scores (F1 scores) of all 3 classifiers. It should also allow the time it takes to train the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data, first_week, normalize=False, decay=False):\n",
    "    # split to train and test\n",
    "    train, test = train_test_split(data)\n",
    "    \n",
    "    # pipeline\n",
    "    pipe = Pipeline([\n",
    "        ('weeks', WeeksLimiter(first_week, target_week)),\n",
    "        ('normal', Normalizer(skip=not normalize)),\n",
    "        ('decay', TimeDecayApplier(target_week, skip=not decay))\n",
    "    ])\n",
    "    \n",
    "    # split data\n",
    "    train_target = train.target\n",
    "    test_target = test.target\n",
    "    train = train.drop('target', axis=1)\n",
    "    test = test.drop('target', axis=1)\n",
    "    \n",
    "    print('Training on', train.shape[0], 'samples')\n",
    "    \n",
    "    # apply pipeline\n",
    "    pipe.fit(train, train_target)\n",
    "    train = pipe.transform(train)\n",
    "    test = pipe.transform(test)\n",
    "    \n",
    "    # classifiers\n",
    "    logistic = LogisticRegression()\n",
    "    bayes = GaussianNB()\n",
    "    tree = DecisionTreeClassifier()\n",
    "    \n",
    "    # train\n",
    "    print('Training logistic regression')\n",
    "    start = timer()\n",
    "    logistic.fit(train, train_target)\n",
    "    end = timer()\n",
    "    logistic_time = end - start\n",
    "    \n",
    "    print('Training naive bayes')\n",
    "    start = timer()\n",
    "    bayes.fit(train, train_target)\n",
    "    end = timer()\n",
    "    bayes_time = end - start\n",
    "    \n",
    "    print('Training decision tree')\n",
    "    start = timer()\n",
    "    tree.fit(train, train_target)\n",
    "    end = timer()\n",
    "    tree_time = end - start\n",
    "    \n",
    "    # predict\n",
    "    logistic_score = f1_score(test_target, logistic.predict(test))\n",
    "    bayes_score = f1_score(test_target, bayes.predict(test))\n",
    "    tree_score = f1_score(test_target, tree.predict(test))\n",
    "    \n",
    "    # return\n",
    "    return logistic_time, logistic_score, bayes_time, bayes_score, tree_time, tree_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous conclusion\n",
    "\n",
    "This was the conclusion before writing the `evaluate` function.\n",
    "\n",
    "With 8 weeks worth of data that is untransformed, the logistic regression performs the best. Naive bayes takes is much quicker to fit but performs poorly. Decision tree has slightly worse scores that logistic regression and it takes quite longer to fit.\n",
    "\n",
    "Decision tree performs the best on the transformed data. It takes very long to train but gives the best scores. Naive bayes performs better than logistic regression and fits the data very quickly. Logistic regression suffers when predicting the active users. It takes very short time to fit compared to the decision tree but performs very poorly.\n",
    "\n",
    "Transforming the data helped for the naive bayes and decision tree but it screwed up the logistic regression.\n",
    "\n",
    "Logistic regression performs the best on untransformed data. Decision tree performs the best on transformed data, even better than the previous logistic regression. However, it takes very long to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "Now we can easily evaluate multiple configurations. Let's play!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_print(weeks, normalize, decay):\n",
    "    logistic_time, logistic_score, bayes_time, bayes_score, tree_time, tree_score = evaluate(data, target_week - weeks, normalize, decay)\n",
    "    \n",
    "    results = pd.DataFrame()\n",
    "    results['time to train in seconds'] = [logistic_time, bayes_time, tree_time]\n",
    "    results['f1 score'] = [logistic_score, bayes_score, tree_score]\n",
    "    results.index = ['logistic regression', 'naive bayes', 'decision tree']\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 1434270 samples\n",
      "Training logistic regression\n",
      "Training naive bayes\n",
      "Training decision tree\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time to train in seconds</th>\n",
       "      <th>f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>5.507904</td>\n",
       "      <td>0.716468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive bayes</th>\n",
       "      <td>0.584380</td>\n",
       "      <td>0.315991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>8.720838</td>\n",
       "      <td>0.719166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time to train in seconds  f1 score\n",
       "logistic regression                  5.507904  0.716468\n",
       "naive bayes                          0.584380  0.315991\n",
       "decision tree                        8.720838  0.719166"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_print(3, normalize=False, decay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 1434270 samples\n",
      "Training logistic regression\n",
      "Training naive bayes\n",
      "Training decision tree\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time to train in seconds</th>\n",
       "      <th>f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>2.272803</td>\n",
       "      <td>0.666470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive bayes</th>\n",
       "      <td>0.521504</td>\n",
       "      <td>0.585638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>7.365648</td>\n",
       "      <td>0.713384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time to train in seconds  f1 score\n",
       "logistic regression                  2.272803  0.666470\n",
       "naive bayes                          0.521504  0.585638\n",
       "decision tree                        7.365648  0.713384"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_print(3, normalize=True, decay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 1434270 samples\n",
      "Training logistic regression\n",
      "Training naive bayes\n",
      "Training decision tree\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time to train in seconds</th>\n",
       "      <th>f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>2.416988</td>\n",
       "      <td>0.666429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive bayes</th>\n",
       "      <td>0.518300</td>\n",
       "      <td>0.587867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>7.481723</td>\n",
       "      <td>0.713577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time to train in seconds  f1 score\n",
       "logistic regression                  2.416988  0.666429\n",
       "naive bayes                          0.518300  0.587867\n",
       "decision tree                        7.481723  0.713577"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_print(3, normalize=True, decay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 1434270 samples\n",
      "Training logistic regression\n",
      "Training naive bayes\n",
      "Training decision tree\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time to train in seconds</th>\n",
       "      <th>f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>12.910996</td>\n",
       "      <td>0.717402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive bayes</th>\n",
       "      <td>1.268664</td>\n",
       "      <td>0.281066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>26.483935</td>\n",
       "      <td>0.713895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time to train in seconds  f1 score\n",
       "logistic regression                 12.910996  0.717402\n",
       "naive bayes                          1.268664  0.281066\n",
       "decision tree                       26.483935  0.713895"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_print(8, normalize=False, decay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 1434270 samples\n",
      "Training logistic regression\n",
      "Training naive bayes\n",
      "Training decision tree\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time to train in seconds</th>\n",
       "      <th>f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>3.622470</td>\n",
       "      <td>0.005953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive bayes</th>\n",
       "      <td>1.215836</td>\n",
       "      <td>0.559784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>22.276630</td>\n",
       "      <td>0.708320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time to train in seconds  f1 score\n",
       "logistic regression                  3.622470  0.005953\n",
       "naive bayes                          1.215836  0.559784\n",
       "decision tree                       22.276630  0.708320"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_print(8, normalize=True, decay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 1434270 samples\n",
      "Training logistic regression\n",
      "Training naive bayes\n",
      "Training decision tree\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time to train in seconds</th>\n",
       "      <th>f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>3.905712</td>\n",
       "      <td>0.666553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive bayes</th>\n",
       "      <td>1.173690</td>\n",
       "      <td>0.552587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>24.014808</td>\n",
       "      <td>0.703270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time to train in seconds  f1 score\n",
       "logistic regression                  3.905712  0.666553\n",
       "naive bayes                          1.173690  0.552587\n",
       "decision tree                       24.014808  0.703270"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_print(8, normalize=True, decay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12 weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 1434270 samples\n",
      "Training logistic regression\n",
      "Training naive bayes\n",
      "Training decision tree\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time to train in seconds</th>\n",
       "      <th>f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>14.289392</td>\n",
       "      <td>0.718820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive bayes</th>\n",
       "      <td>1.797675</td>\n",
       "      <td>0.273473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>37.939056</td>\n",
       "      <td>0.764517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time to train in seconds  f1 score\n",
       "logistic regression                 14.289392  0.718820\n",
       "naive bayes                          1.797675  0.273473\n",
       "decision tree                       37.939056  0.764517"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_print(12, normalize=False, decay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 1434270 samples\n",
      "Training logistic regression\n",
      "Training naive bayes\n",
      "Training decision tree\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time to train in seconds</th>\n",
       "      <th>f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>14.583505</td>\n",
       "      <td>0.718946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive bayes</th>\n",
       "      <td>1.768697</td>\n",
       "      <td>0.273817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>42.113433</td>\n",
       "      <td>0.765420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time to train in seconds  f1 score\n",
       "logistic regression                 14.583505  0.718946\n",
       "naive bayes                          1.768697  0.273817\n",
       "decision tree                       42.113433  0.765420"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_print(12, normalize=False, decay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 1434270 samples\n",
      "Training logistic regression\n",
      "Training naive bayes\n",
      "Training decision tree\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time to train in seconds</th>\n",
       "      <th>f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>4.474290</td>\n",
       "      <td>0.044247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive bayes</th>\n",
       "      <td>1.742707</td>\n",
       "      <td>0.550220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>33.730065</td>\n",
       "      <td>0.705697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time to train in seconds  f1 score\n",
       "logistic regression                  4.474290  0.044247\n",
       "naive bayes                          1.742707  0.550220\n",
       "decision tree                       33.730065  0.705697"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_print(12, normalize=True, decay=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
